{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: using Linear Programming to solve for 3 latent factors `w`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the last part of this example, \"Permutation invariance in linear programming vs. MultiCCA in R and `pmd`\" requires that `inpt3` be exactly as printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sparsecca import lp_pmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example inputs\n",
    "inpt1 = pd.read_csv(\"../tests/data/multicca1.csv\", sep=\",\", index_col=0).values\n",
    "inpt2 = pd.read_csv(\"../tests/data/multicca2.csv\", sep=\",\", index_col=0).values[:, -5:]\n",
    "inpt3 = np.random.normal(size=inpt2.shape)\n",
    "\n",
    "penalties = [1.5, 1.5, 1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.16289006, -1.10155538, -0.07361009, -1.04768133, -0.23030313],\n",
       "       [-0.28524699, -0.95404835,  1.25754511,  2.22141375, -0.64806753],\n",
       "       [-0.80371799, -0.09921252, -1.30902827, -0.12490934, -0.53780387],\n",
       "       [ 1.23123296,  1.30839663,  2.35443782,  1.2004608 , -0.24753196],\n",
       "       [ 1.24686808,  0.2176884 , -0.51074504,  1.68211628, -0.0589116 ],\n",
       "       [-0.54485555, -0.31221068, -0.72426958,  0.11262969,  0.06324836],\n",
       "       [-1.36002346, -2.02609761, -0.77052108, -1.47716523, -0.98507913],\n",
       "       [ 2.01516562, -0.35919419,  0.98862972, -0.30120967, -1.85093266],\n",
       "       [-1.43260253, -0.00428044, -0.31457342,  0.72451216,  0.59311224],\n",
       "       [-0.46268311,  2.11013054, -0.80026669,  0.03718434, -0.66038343],\n",
       "       [ 1.79330705, -1.77072566,  0.59342351,  0.5705045 , -0.26306724],\n",
       "       [-0.53183765,  0.46836312, -0.16679474,  0.24751673,  0.48850261],\n",
       "       [ 0.64762214, -0.2314719 , -0.00601488, -1.31931633, -0.02510419],\n",
       "       [-0.0595952 , -1.14180706,  0.10746787, -0.35318886, -0.07661414],\n",
       "       [-0.57148704,  0.79014662, -0.18573718,  1.04355359,  1.57775996],\n",
       "       [ 1.29146116,  0.02004213,  0.69239577,  2.35286   , -1.56292662],\n",
       "       [ 1.62873882, -1.23221121,  1.65388461, -0.3126268 , -0.7598255 ],\n",
       "       [-1.62725948,  0.59066322,  0.97152531, -1.20732746, -0.8981499 ],\n",
       "       [-1.32635761,  0.49787141, -1.41803712,  1.21642253, -0.06228299],\n",
       "       [-0.82386691,  2.90123106,  0.50903272,  0.90469804, -0.51054396],\n",
       "       [-0.51186988, -0.90623346, -0.09036516, -0.21023619,  0.17084248],\n",
       "       [-0.57207486,  0.42464088,  0.51752789, -0.8194987 ,  3.15266947],\n",
       "       [ 1.05896183,  1.39600636,  0.86299409,  0.79002278, -0.59867327],\n",
       "       [-1.90949454,  0.09847346, -0.92126405,  0.53865328,  2.028253  ],\n",
       "       [-0.83438946, -0.36229773, -1.29525538,  2.04590215,  1.0633799 ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, svd_init = lp_pmd(\n",
    "    datasets=[inpt1, inpt2], # match feature dimension for now\n",
    "    penalties=penalties[:2],\n",
    "    K=3,\n",
    "    standardize=True,\n",
    "    mimic_R=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.08911592,  0.05447262, -0.17954319],\n",
       "        [ 0.66470561, -0.54663329,  0.6135666 ],\n",
       "        [ 0.60794117, -0.65622806,  0.55246482],\n",
       "        [-0.42496254,  0.42511018, -0.52736503],\n",
       "        [-0.0062595 , -0.29473863, -0.08926939]],\n",
       "\n",
       "       [[ 0.49615515, -0.43360575,  0.50388569],\n",
       "        [ 0.30569572, -0.57468281,  0.2926027 ],\n",
       "        [-0.13754639, -0.06168402, -0.09398377],\n",
       "        [-0.73325299,  0.47846533, -0.74173363],\n",
       "        [ 0.32218201, -0.49899073,  0.31856108]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between pmd results and lp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sparsecca import multicca_pmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### high correlation between pmd and lp when `n=2`\n",
    "\n",
    "Let `n` equal the number of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [inpt1, inpt2]\n",
    "ws_lp, _ = lp_pmd(datasets, penalties[:2])\n",
    "ws_r, _ = multicca_pmd(datasets, penalties[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=0.9746794344808964, pvalue=0.004818230468198537)\n",
      "SignificanceResult(statistic=0.8999999999999998, pvalue=0.03738607346849874)\n"
     ]
    }
   ],
   "source": [
    "print(spearmanr(ws_lp[0], ws_r[0]))\n",
    "print(spearmanr(ws_lp[1], ws_r[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is the same as taking the first latent factor when K=3, as per the implementation in Witten 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=0.9746794344808964, pvalue=0.004818230468198537)\n",
      "SignificanceResult(statistic=0.8999999999999998, pvalue=0.03738607346849874)\n"
     ]
    }
   ],
   "source": [
    "print(spearmanr(weights[0].T[0], ws_r[0]))\n",
    "print(spearmanr(weights[1].T[0], ws_r[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arbitrarily lower correlation when `n=3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare when `n=3`. Note that this is subject to the same warning as in the bottom of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [inpt1, inpt2, inpt3]\n",
    "ws_lp, _ = lp_pmd(datasets, penalties[:3])\n",
    "ws_r, _ = multicca_pmd(datasets, penalties[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=-0.8720815992723809, pvalue=0.05385421772754211)\n",
      "SignificanceResult(statistic=-0.35909242322980395, pvalue=0.5528147466433505)\n",
      "SignificanceResult(statistic=-0.09999999999999999, pvalue=0.8728885715695383)\n"
     ]
    }
   ],
   "source": [
    "print(spearmanr(ws_lp[0], ws_r[0]))\n",
    "print(spearmanr(ws_lp[1], ws_r[1]))\n",
    "print(spearmanr(ws_lp[2], ws_r[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization of the objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the objective function, which was maximized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st pair: [[111.69927657]]\n",
      "2nd pair: [[16.09054608]]\n",
      "3rd pair: [[29.41034686]]\n",
      "sum [[157.20016951]]\n"
     ]
    }
   ],
   "source": [
    "print('1st pair:', ws_lp[0].T @ inpt1.T @ inpt2 @ ws_lp[1])\n",
    "print('2nd pair:', ws_lp[1].T @ inpt2.T @ inpt3 @ ws_lp[2])\n",
    "print('3rd pair:', ws_lp[2].T @ inpt3.T @ inpt1 @ ws_lp[0])\n",
    "print('sum', ws_lp[0].T @ inpt1.T @ inpt2 @ ws_lp[1] + ws_lp[1].T @ inpt2.T @ inpt3 @ ws_lp[2] + ws_lp[2].T @ inpt3.T @ inpt1 @ ws_lp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st pair: [[108.09846793]]\n",
      "2nd pair: [[21.92976799]]\n",
      "3rd pair: [[30.2407647]]\n",
      "sum [[160.26900062]]\n"
     ]
    }
   ],
   "source": [
    "print('1st pair:', ws_r[0].T @ inpt1.T @ inpt2 @ ws_r[1])\n",
    "print('2nd pair:', ws_r[1].T @ inpt2.T @ inpt3 @ ws_r[2])\n",
    "print('3rd pair:', ws_r[2].T @ inpt3.T @ inpt1 @ ws_r[0])\n",
    "print('sum', ws_r[0].T @ inpt1.T @ inpt2 @ ws_r[1] + ws_r[1].T @ inpt2.T @ inpt3 @ ws_r[2] + ws_r[2].T @ inpt3.T @ inpt1 @ ws_r[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 norm of the latent factors, constrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508160371626"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(ws_lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(ws_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither linear programming nor manual convergence consistently produces a better optimization of the objective function in this small test case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation invariance in linear programming vs. MultiCCA in R and `pmd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_weights(weights_a, weights_b, perm_b: list[int], dec=5):\n",
    "    \"\"\"Tests whether `weights_a` and `weights_b` are the same given the permutation order of b.\n",
    "\n",
    "    Parameters:\n",
    "        weights_a: output of lp_pmd \n",
    "        weights_b: output of lp_pmd permuted Xn\n",
    "                   -> weights are of type np.ndarray in shape (N, f, K)\n",
    "                    - N: len(Xn) datasets\n",
    "                    - f: amount of features\n",
    "                    - K: amount of MCPs\n",
    "        perm_b:    order of the datasets used to generate a, in b\n",
    "        dec:       decimals to which weights should be rounded to account for numerical tolerance\n",
    "\n",
    "    Returns:\n",
    "        boolean: True if rounded weights are the same, else False\n",
    "    \"\"\"\n",
    "    \n",
    "    weights_a_rounded = weights_a.round(decimals=dec)\n",
    "    weights_b_rounded = weights_b.round(decimals=dec)\n",
    "    \n",
    "    weights_b_ordered = []\n",
    "    for o in perm_b:\n",
    "        weights_b_ordered.append(weights_b_rounded[o])\n",
    "        \n",
    "    return all(x==True for x in (weights_a_rounded==weights_b_ordered).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [inpt1, inpt2, inpt3]\n",
    "# original dataset with perm 1, 2, 0\n",
    "datasets_perm = [inpt3, inpt1, inpt2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ws_lp, _ = lp_pmd(datasets, penalties)\n",
    "ws_lp_perm, _ = lp_pmd(datasets_perm, penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.06329702],\n",
       "        [-0.47883099],\n",
       "        [-0.71653621],\n",
       "        [ 0.50235555],\n",
       "        [-0.03048172]],\n",
       "\n",
       "       [[-0.35167889],\n",
       "        [-0.48543111],\n",
       "        [-0.07157119],\n",
       "        [ 0.54892933],\n",
       "        [-0.57812867]],\n",
       "\n",
       "       [[-0.74880871],\n",
       "        [-0.52826939],\n",
       "        [-0.39417701],\n",
       "        [ 0.00182197],\n",
       "        [ 0.06955682]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.74880871],\n",
       "        [-0.52826939],\n",
       "        [-0.39417701],\n",
       "        [ 0.00182197],\n",
       "        [ 0.06955682]],\n",
       "\n",
       "       [[-0.06329702],\n",
       "        [-0.47883099],\n",
       "        [-0.71653621],\n",
       "        [ 0.50235555],\n",
       "        [-0.03048172]],\n",
       "\n",
       "       [[-0.35167889],\n",
       "        [-0.48543111],\n",
       "        [-0.07157119],\n",
       "        [ 0.54892933],\n",
       "        [-0.57812867]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_lp_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights(ws_lp, ws_lp_perm, [1,2,0], dec=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the weights are the same with merely the order permuted as is appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R (in python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_r, _ = multicca_pmd(datasets, penalties)\n",
    "ws_r_perm, _ = multicca_pmd(datasets_perm, penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.        ],\n",
       "        [ 0.8315665 ],\n",
       "        [ 0.54048778],\n",
       "        [-0.12794572],\n",
       "        [-0.        ]]),\n",
       " array([[ 0.72935664],\n",
       "        [-0.0928381 ],\n",
       "        [-0.        ],\n",
       "        [-0.67780527],\n",
       "        [ 0.        ]]),\n",
       " array([[ 0.        ],\n",
       "        [ 0.89010769],\n",
       "        [-0.42640703],\n",
       "        [-0.15901786],\n",
       "        [ 0.02446747]])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.12178605],\n",
       "        [ 0.93963595],\n",
       "        [-0.27441203],\n",
       "        [-0.16416603],\n",
       "        [ 0.        ]]),\n",
       " array([[-0.        ],\n",
       "        [ 0.75371432],\n",
       "        [ 0.65012982],\n",
       "        [-0.09615587],\n",
       "        [-0.        ]]),\n",
       " array([[ 0.73184218],\n",
       "        [-0.        ],\n",
       "        [-0.        ],\n",
       "        [-0.67508905],\n",
       "        [ 0.09306875]])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_r_perm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with decimal tolerance 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights(np.array(ws_r), np.array(ws_r_perm), [1,2,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with decimal tolerance 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights(np.array(ws_r), np.array(ws_r_perm), [1,2,0], dec=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the equivalent negative solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights(np.array(ws_r), -np.array(ws_r_perm), [1,2,0], dec=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: linear programming will always solve for the same objective function regardless of the order of the inputs, but the custom PMD implementation in `multicca_pmd` will not. Depending on the dataset, the solution may converge similarly regardless of order (with only a difference in sign), or the solution may converge to a completely different local minima given a different order."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sparsecca]",
   "language": "python",
   "name": "conda-env-sparsecca-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
